## Pod is Stuck in CrashLoopBackOff â€“ What Steps Will You Take?

### Question  
Your Kubernetes pod is stuck in the `CrashLoopBackOff` state. How would you troubleshoot and resolve this issue?

### Short explanation of the question  
This scenario tests your ability to debug failing pods in Kubernetes, especially when containers crash repeatedly due to application or environment-related issues.

---

### Answer  
To troubleshoot a `CrashLoopBackOff`, I would check pod logs, container events, and resource limits. Common causes include application bugs, incorrect configs, failed dependencies, or OOM errors. Iâ€™d resolve the root cause based on these findings.

---

### Detailed explanation of the answer for readersâ€™ understanding

---

### ğŸ” Step-by-Step Troubleshooting Process

---

#### 1. ğŸ” Check Pod Status and Reason

```bash
kubectl get pod <pod-name> -n <namespace>
kubectl describe pod <pod-name> -n <namespace>
```

Look under **"Last State"**, **"Exit Code"**, and **"Events"** to understand whatâ€™s causing the container crash.

---

#### 2. ğŸ“„ View Container Logs

```bash
kubectl logs <pod-name> -c <container-name> --previous -n <namespace>
```

Use `--previous` to see logs from the last failed attempt. Youâ€™ll often find stack traces, errors like:

- `Connection refused`
- `File not found`
- `Segmentation fault`
- `Permission denied`

---

#### 3. âš™ï¸ Check for Configuration or Secret Issues

- Did the pod mount a ConfigMap or Secret thatâ€™s missing or misconfigured?
- Are environment variables or command-line arguments set incorrectly?

```bash
kubectl describe pod <pod-name>
```

---

#### 4. ğŸ“¦ Check for Missing Dependencies

- Is the container trying to connect to a service thatâ€™s not running?
- Is a database unavailable or unreachable?
- Are DNS entries resolving?

---

#### 5. ğŸ’½ Check Resource Constraints

```bash
kubectl describe pod <pod-name>
```

If it shows:
```
Reason: OOMKilled
```
Then the container exceeded memory limits. Youâ€™ll need to increase memory in the spec or optimize the application.

---

#### 6. ğŸ› Check Image, CMD, ENTRYPOINT

Sometimes the crash is because of:

- Wrong image version
- Entry command missing a binary
- Script missing execute permissions

You can test locally with Docker or `kubectl run` to isolate the issue.

---

#### 7. ğŸ§ª Use Ephemeral Container for Debugging (K8s v1.23+)

```bash
kubectl debug -it <pod-name> --image=busybox --target=<container-name>
```

You can inspect volumes, paths, env variables while the pod crashes repeatedly.

---

### ğŸ› ï¸ Real-World Fix Example

> â€œIn one case, our pod crashed due to a ConfigMap change that removed a required ENV variable. We restored the variable, restarted the pod, and it worked. Another time, we hit an OOMKilled issue and increased memory limits from 256Mi to 512Mi.â€

---

### Key takeaway  

> `CrashLoopBackOff` means your container is repeatedly failing and restarting. The fix depends on identifying the **root cause via logs, events, configs, and resource usage** â€” not just restarting the pod.
